---
title: 'Chapter 13: Classification'
output: html_document
---

```{r setup, include=FALSE}
# Thanks to Seaam Noor for some excellent work on this script.

# There are two packages which you need to install.

# install.packages("tidymodels")
# install.packages("rpart.plot")
# install.packages("randomForest")

knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(infer)
library(skimr)
library(gganimate)
library(rpart.plot)
library(tidymodels)
library(tidyverse)

# tidymodels really wants your dependent variable to be a factor. After all, you
# have told tidymodels that it is not really a number --- it is a category with
# two possible values. Keeping it as a 0/1 numeric is a hack. So, create a new
# variable, `vote` which is either Democrat or Republican. In order to make the
# coefficients have the same sign as they did on Tuesday, I change the default
# ordering of the factor levels.

nes <- read_rds("ch13_nes.rds") %>% 
  mutate(vote = factor(ifelse(dvote == 1, "Democrat", "Republican"), 
                          levels = c("Republican", "Democrat")))
```


# Before we start

Here is the [chapter titled "Classification"](https://davidkane9.github.io/PPBDS/13-classification.html) that this class is based on. The data has been taken from the National Election Survey. Note that both ideology and party are measured in 7 point scales. `ideology` ranges from Strong liberal (1) to Strong Conservative (7). `party` ranges from Strong Democrat (1) to Strong Republican (7). `income` is measured on a 5 point scale ranging from very poor (1) to very rich (5). You may treat these variables as continuous. `vote`  is our outcome variable. It is "Democrat" if the person prefers the Democratic candidate for President and "Republican" otherwise.

We are using the [**tidymodels** collection of packages](https://www.tidymodels.org/) today, the more modern/professional approach to creating models in R.

# Scene 1

**Prompt:** Following [the approach](https://davidkane9.github.io/PPBDS/13-classification.html#professional-models) outlined in the *Primer*, use **tidymodels** to estimate a logistic regression in which `vote` is the dependent variable and `ideology`, `income`, `gender`, and `race` are the independent variables. 

Useful functions include `logistic_reg()`, `set_engine()`, and `fit()`.

Interpret the coefficient of `income`.

Write a sentence to your smart-but-not-mathematical boss which explains the association of income with preference for the Democratic candidate. Include a notion of uncertainty.

```{r Scene 1, echo = FALSE}

# Save model specification

logistic_mod <- logistic_reg() %>%
  set_engine("glm")

logistic_fit <- fit(logistic_mod,
                    factor(vote) ~ ideology + income + gender + race,
                    data = nes)

logistic_fit$fit %>% 
  tidy(conf.int = TRUE) %>% 
  select(term, estimate, conf.low, conf.high)

```

Holding all other variables constant, an increase in 1 unit of income is associated with a -0.21517677 / 4 change in probability to vote for a democratic candidate. 

We are 95% confident that increasing the income level by 1 unit for a given individual has an effect on probability of voting for a democratic candidate between -.2718516/4 and -0.15860716/4. 

If we divide the US population


# Scene 2

**Prompt:** Review [CART models](https://davidkane9.github.io/PPBDS/13-classification.html#classification-and-regression-trees-cart). Using the all the same independent variables as in Scene 1, estimate a CART model in which `vote` is the dependent variable.

Hint: In addition to the functions you used in Scene 1, you may find `set_mode()` and `prp()` to be helpful.

Print the fitted model.

Plot the fitted model. You may find the `prp()` function to be useful. I like `extra = 6` as an argument. Read the help page to understand what it means.

Write two sentences explaining to your smart-but-not-mathematical boss what the model means and how he should interpret it. Make sure to discuss why some variables, like gender, are not used in the model. He thinks that gender matters to voting!

Optional: Can you write a simple dplr pipe which does, more or less, what the CART is doing, at least for the first node, and then confirms the numbers in the plot?

```{r Scene 2, echo = FALSE}

tree_mod <- decision_tree() %>%
  set_engine("rpart",
             model = TRUE) %>%
  set_mode("classification")

nes_tree <- fit(tree_mod,
                factor(vote) ~ ideology + income + gender + race, 
                data = nes)

nes_tree$fit %>% 
    prp(extra = 6, varlen = 0, faclen = 0)

nes %>% filter(! ideology >= 4) %>% summarise(total = n(), dems =sum(vote == "Democratic")) %>% mutate(per=dems/total)

```

If liberal (123), 79% will vote democrat

If not liberal, ???????

# Scene 3

**Prompt:** Following [the approach](https://davidkane9.github.io/PPBDS/13-classification.html#random-forests) outlined in the *Primer*, use **tidymodels** to estimate a random forest model in which `vote` is the dependent variable and `ideology`, `income`, `gender`, and `race` are the independent variables. 

Hint: In addition to the functions you used in Scenes 1 and 2, you may find `rand_forest()` to be helpful.

Print out and interpret the model.

How many trees did the forest use? Would we get better results if we used a different number of trees?

What is OOB error?

```{r Scene 3, echo = FALSE}

forest_mod <- rand_forest() %>%
  set_engine("randomForest") %>%
  set_mode("classification")

house_forest <- fit(forest_mod,
                    factor(vote) ~ ideology + income + gender + race, 
                     data = nes)

house_forest

tibble(`Error rate` = house_forest$fit$err.rate[, "OOB"],
       Trees = 1:500) %>%
  ggplot(aes(x = Trees, y = `Error rate`)) +
  geom_line() +
  theme_classic()

```
500 Trees. Maybe margnially better if we used more trees but it largely plateaus by 500 trees

The OOB error is 25.3%

# Scene 4

**Prompt:** Weâ€™ve explored three ways to model binary responses in this chapter. Compare the accuracy of predictions of `logistic` vs `cart` vs `forest` on our `nes` data. Here are the steps to follow:

1. Use the models we have already estimated.

2. Add columns of each model's prediction on `nes` by using `mutate` on `nes`. You should use `predict` and feed it the saved model and `new_data = nes`. `pull()` the `.pred_class` from the prediction. 

3. Create a tibble with the accuracy of the prediction columns of each model.

4. Is accuracy the metric to use? Would using sensitivity or specificity be more appropriate?

Note:
Accuracy = (Actual 1 as 1 + Actual 0 as 0) / n
Sensitivity = The proportion of actual 1s classified as 1
Specificity = The proportion of actual 0s classified as 0

```{r Accuracy of models}
nes_vote_predictions <- nes %>% 
  mutate(logistics = predict(logistic_fit, new_data = nes) %>%  pull(.pred_class),
         tree = predict(nes_tree, new_data = nes) %>% pull(.pred_class),
         forest = predict(house_forest, new_data = nes) %>%  pull(.pred_class)) %>% 
  select(vote, logistics, tree, forest) 

tibble(logistics = mean(nes_vote_predictions$logistics == nes_vote_predictions$vote),
       tree = mean(nes_vote_predictions$tree == nes_vote_predictions$vote),
       forest = mean(nes_vote_predictions$forest == nes_vote_predictions$vote))

```


# Challenge Problem

Make a cool animation with the nes data, using [this package](https://github.com/daranzolin/d3rain). Put the animation in an Rpubs page. Here are the animations which students in 1006 made yesterday (with different data):

https://rpubs.com/rmckenzie11/599663   
https://rpubs.com/evelyncai/d3rain_practice   
https://rpubs.com/diego_martinez/d3rain   

Surely, you can make something better than what they did! You also have a much richer data set to play with than they had. Maybe separate panels for different years. Maybe voters rain down from different income or ideology categories across the top? There are many possibilities! Add a link with to [today's Preceptor's Notes](https://piazza.com/class/k5y1jx0s5ibe1?cid=721).
